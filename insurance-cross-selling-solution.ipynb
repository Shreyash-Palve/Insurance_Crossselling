{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":73291,"databundleVersionId":8930475,"sourceType":"competition"},{"sourceId":1480773,"sourceType":"datasetVersion","datasetId":869050},{"sourceId":7349720,"sourceType":"datasetVersion","datasetId":4268036},{"sourceId":9079083,"sourceType":"datasetVersion","datasetId":5418885}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.utils import check_array\nfrom sklearn.base import clone\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport warnings\nimport pickle\nimport glob\nimport gc\n\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-29T16:42:12.904024Z","iopub.status.idle":"2024-07-29T16:42:17.550013Z","shell.execute_reply.started":"2024-07-29T16:42:12.904955Z","shell.execute_reply":"2024-07-29T16:42:17.54881Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 90\nN_FOLDS = 5\nTARGET = 'Response'","metadata":{"execution":{"iopub.status.busy":"2024-07-29T16:42:17.552349Z","iopub.execute_input":"2024-07-29T16:42:17.552934Z","iopub.status.idle":"2024-07-29T16:42:17.558174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s4e7/train.csv')\noriginal = pd.read_csv('/kaggle/input/health-insurance-cross-sell-prediction-data/train.csv', index_col='id')","metadata":{"execution":{"iopub.status.busy":"2024-07-29T16:42:17.570039Z","iopub.execute_input":"2024-07-29T16:42:17.57048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.concat([train, original]).reset_index(drop=True) \ntrain = train.drop_duplicates(keep=\"last\").reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.drop(columns=TARGET)\ny = train[TARGET]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_scores(oof_pred_probs):\n    scores = []\n    skf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n        y_val = y[val_idx]\n        y_pred_probs = oof_pred_probs[val_idx]          \n        score = roc_auc_score(y_val, y_pred_probs[:, 1])\n        scores.append(score)\n    return scores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred_probs = {}\noof_pred_probs = {}\nscores = {}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_oof_pred_probs_files = glob.glob('/kaggle/input/insurance-cross-selling-oof-files/xgboost/xgb_oof_pred_probs_*.pkl')\nxgb_test_pred_probs_files = glob.glob('/kaggle/input/insurance-cross-selling-oof-files/xgboost/xgb_test_pred_probs_*.pkl')\n\nxgb_oof_pred_probs = pickle.load(open(xgb_oof_pred_probs_files[0], 'rb'))\nxgb_test_pred_probs = pickle.load(open(xgb_test_pred_probs_files[0], 'rb'))\n\noof_pred_probs['XGBoost'] = xgb_oof_pred_probs\ntest_pred_probs['XGBoost'] = xgb_test_pred_probs\nscores['XGBoost'] = get_scores(xgb_oof_pred_probs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm_oof_pred_probs_files = glob.glob('/kaggle/input/insurance-cross-selling-oof-files/lightgbm/lgbm_oof_pred_probs_*.pkl')\nlgbm_test_pred_probs_files = glob.glob('/kaggle/input/insurance-cross-selling-oof-files/lightgbm/lgbm_test_pred_probs_*.pkl')\n\nlgbm_oof_pred_probs = pickle.load(open(lgbm_oof_pred_probs_files[0], 'rb'))\nlgbm_test_pred_probs = pickle.load(open(lgbm_test_pred_probs_files[0], 'rb'))\n\noof_pred_probs['LightGBM'] = lgbm_oof_pred_probs\ntest_pred_probs['LightGBM'] = lgbm_test_pred_probs\nscores['LightGBM'] = get_scores(lgbm_oof_pred_probs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"catboost_oof_pred_probs_files = glob.glob('/kaggle/input/insurance-cross-selling-oof-files/catboost/catboost_oof_pred_probs_*.pkl')\ncatboost_test_pred_probs_files = glob.glob('/kaggle/input/insurance-cross-selling-oof-files/catboost/catboost_test_pred_probs_*.pkl')\n\ncatboost_oof_pred_probs = pickle.load(open(catboost_oof_pred_probs_files[0], 'rb'))\ncatboost_test_pred_probs = pickle.load(open(catboost_test_pred_probs_files[0], 'rb'))\n\noof_pred_probs['CatBoost'] = catboost_oof_pred_probs\ntest_pred_probs['CatBoost'] = catboost_test_pred_probs\nscores['CatBoost'] = get_scores(catboost_oof_pred_probs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ann_oof_pred_probs_files = glob.glob('/kaggle/input/insurance-cross-selling-oof-files/keras/keras_oof_pred_probs_*.pkl')\nann_test_pred_probs_files = glob.glob('/kaggle/input/insurance-cross-selling-oof-files/keras/keras_test_pred_probs_*.pkl')\n\nann_oof_pred_probs = pickle.load(open(ann_oof_pred_probs_files[0], 'rb'))\nann_test_pred_probs = pickle.load(open(ann_test_pred_probs_files[0], 'rb'))\n\noof_pred_probs['KerasANN'] = ann_oof_pred_probs\ntest_pred_probs['KerasANN'] = ann_test_pred_probs\nscores['KerasANN'] = get_scores(ann_oof_pred_probs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_oof_pred_probs_files = glob.glob('/kaggle/input/insurance-cross-selling-oof-files/logistic-regression/logisticregression_oof_pred_probs_*.pkl')\nlr_test_pred_probs_files = glob.glob('/kaggle/input/insurance-cross-selling-oof-files/logistic-regression/logisticregression_test_pred_probs_*.pkl')\n\nlr_oof_pred_probs = pickle.load(open(lr_oof_pred_probs_files[0], 'rb'))\nlr_test_pred_probs = pickle.load(open(lr_test_pred_probs_files[0], 'rb'))\n\noof_pred_probs['LogisticRegression'] = lr_oof_pred_probs\ntest_pred_probs['LogisticRegression'] = lr_test_pred_probs\nscores['LogisticRegression'] = get_scores(lr_oof_pred_probs)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, model, n_folds=N_FOLDS):\n        self.model = model\n        self.n_folds = n_folds\n\n    def fit_predict(self, X, y, X_test):\n        print(f'Training {self.model.__class__.__name__}')\n        \n        scores = []\n        oof_pred_probs = np.zeros((X.shape[0], len(np.unique(y))))\n        test_pred_probs = np.zeros((X_test.shape[0], len(np.unique(y))))\n        \n        skf = StratifiedKFold(n_splits=self.n_folds, random_state=SEED, shuffle=True)\n        for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n            y_train, y_val = y[train_idx], y[val_idx]\n            \n            model = clone(self.model)\n            model.fit(X_train, y_train)\n            \n            y_pred_probs = model.predict_proba(X_val)    \n            oof_pred_probs[val_idx] = y_pred_probs          \n            score = roc_auc_score(y_val, y_pred_probs[:, 1])\n            scores.append(score)\n            \n            temp_test_pred_probs = model.predict_proba(X_test)\n            test_pred_probs += temp_test_pred_probs / self.n_folds\n            \n            del model\n            gc.collect()\n            \n            print(f'--- Fold {fold_idx + 1} - AUC: {score:.5f}')\n            \n        print(f'------ Average AUC: {np.mean(scores):.5f} Â± {np.std(scores):.5f}')\n        \n        self._save_submission(test_pred_probs, np.mean(scores))\n        \n        return oof_pred_probs, scores\n    \n    def _save_submission(self, test_pred_probs, score):\n        name = self.model.__class__.__name__.lower().replace('classifier', '')\n        sub = pd.read_csv('/kaggle/input/playground-series-s4e7/sample_submission.csv')\n        sub['id'] = sub['id']\n        sub[TARGET] = test_pred_probs[:, 1]\n        # Referencee https://www.kaggle.com/code/paddykb/a-glitch-in-the-insurance-matrix\n        INPUT_DIR = Path('/kaggle/input/playground-series-s4e7')\n        train_data = pd.read_csv(INPUT_DIR / 'train.csv')\n        test_data = pd.read_csv(INPUT_DIR / 'test.csv')\n        orig_data = pd.read_csv('/kaggle/input/health-insurance-cross-sell-prediction/train.csv')\n        features = sorted(set(test_data.columns) - set(['id']))\n        train_data.merge(orig_data, on=features).filter(['Response_x', 'Response_y']).value_counts().reset_index()\n        override_sub = test_data.merge(orig_data.drop(columns=['id']), on=features).assign(override=lambda x: np.where(x['Response'] == 0, 1, 0)).filter(['id', 'override']).groupby(['id'], as_index=False).agg(override=('override', 'mean'))\n        sub.merge(override_sub, how='outer').assign(Response=lambda x: np.where(x['override'].isna(), x['Response'], x['override'])).filter(['id', 'Response']).to_csv(f'sub_{name}_{score:.5f}.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reference: https://www.kaggle.com/competitions/playground-series-s4e6/discussion/509353#2851035\nclass PassThroughClassifier(BaseEstimator, ClassifierMixin):\n    def __init__(self, idx_cols):\n        self.idx_cols = idx_cols\n        self.is_fitted_ = True\n\n    def fit(self, X, y=None):\n        return self\n\n    def predict_proba(self, X):\n        return check_array(X)[:, self.idx_cols]\n\nestimators = [\n    ('XGBoost',             PassThroughClassifier(list(range(0, 2)))),\n    ('LightGBM',            PassThroughClassifier(list(range(2, 4)))),\n    ('CatBoost',            PassThroughClassifier(list(range(4, 6)))),\n    ('KerasANN',            PassThroughClassifier(list(range(6, 8)))),\n    ('LogisticRegression',  PassThroughClassifier(list(range(8, 10)))),\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = np.log(pd.DataFrame(np.hstack(list(oof_pred_probs.values()))) + 1e-7)\nX_test = np.log(pd.DataFrame(np.hstack(list(test_pred_probs.values()))) + 1e-7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacking_model = StackingClassifier(estimators, cv='prefit', n_jobs=-1)\nstacking_trainer = Trainer(stacking_model)\nstacking_oof_pred_probs, stacking_scores = stacking_trainer.fit_predict(X_train, y, X_test)\nscores['Stacking'] = stacking_scores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = pd.DataFrame(scores)\nscores","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 7))\n\nfpr, tpr, _ = roc_curve(y, stacking_oof_pred_probs[:, 1])\naxes[0].plot(fpr, tpr, label=f'AUC: {np.mean(stacking_scores):.5f}', color='#651FFF')\naxes[0].plot([0, 1], [0, 1], color='black', linestyle='--')\naxes[0].set_xlabel('False Positive Rate')\naxes[0].set_ylabel('True Positive Rate')\naxes[0].legend()\naxes[0].grid(True)\naxes[0].set_aspect('equal', adjustable='box')\n\ny_pred = stacking_oof_pred_probs.argmax(axis=1)\ncm = confusion_matrix(y, y_pred)\nsns.heatmap(\n    cm, \n    annot=True, \n    fmt=',', \n    ax=axes[1], \n    cbar=False,\n    cmap=sns.light_palette('#651FFF', reverse=False, as_cmap=True), \n)\naxes[1].set_xlabel('Predicted')\naxes[1].set_ylabel('Actual')\naxes[1].set_aspect('equal', adjustable='box')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_scores = scores.mean().sort_values(ascending=False)\norder = scores.mean().sort_values(ascending=False).index.tolist()\n\nmin_score = mean_scores.min()\nmax_score = mean_scores.max()\npadding = (max_score - min_score) * 0.1\nlower_limit = min_score - padding\nupper_limit = max_score + padding\n\nfig, axs = plt.subplots(1, 2, figsize=(15, 5))\n\nsns.boxplot(data=scores, order=order, ax=axs[0], orient='h', color='#651FFF')\naxs[0].set_title('Fold AUC')\naxs[0].set_xlabel('')\naxs[0].set_ylabel('')\n\nbarplot = sns.barplot(x=mean_scores.values, y=mean_scores.index, ax=axs[1], color='#651FFF')\naxs[1].set_title('Average AUC')\naxs[1].set_xlabel('')\naxs[1].set_xlim(left=lower_limit, right=upper_limit)\naxs[1].set_ylabel('')\n\nfor i, score in enumerate(mean_scores.values):\n    barplot.text(score, i, round(score, 5), va='center')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}